import streamlit as st
import pandas as pd
import json
import os

st.set_page_config(page_title="Read & Rise", layout="wide")

# æ¸…çˆ½æ ·å¼æ³¨å…¥
st.markdown("""
    <style>
    .stApp { background-color: #F8FAFC; }
    .vocab-card { background: white; border-left: 5px solid #10416F; padding: 15px; border-radius: 8px; margin-bottom: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    .book-card { background: white; padding: 25px; border-radius: 15px; border: 1px solid #E2E8F0; margin-bottom: 20px; }
    </style>
""", unsafe_allow_html=True)

def load_data():
    if os.path.exists("data.json"):
        try:
            with open("data.json", "r", encoding="utf-8") as f:
                return json.load(f)
        except: return {"articles": [], "books": []}
    return {"articles": [], "books": []}

data = load_data()

# ä¾§è¾¹æ å¯¼èˆª
with st.sidebar:
    st.title("ğŸ¹ Read & Rise")
    menu = st.radio("é¢‘é“", ["ğŸ  ä¸»é¡µ", "ğŸš€ ä»Šæ—¥å†…å‚", "ğŸ“š ç²¾è¯»ç¬”è®°", "ğŸ§  æ€ç»´æ¨¡å‹", "ğŸ™ï¸ è‹±æ–‡æ•™ç»ƒ"])

# --- é¢‘é“ 2: ç²¾è¯»ç¬”è®° ---
if menu == "ğŸ“š ç²¾è¯»ç¬”è®°":
    st.header("ğŸ“š AI é¢†è¯»ï¼šç²¾è‹±ç²¾è¯»ç¬”è®°")
    if not data.get("books"):
        st.info("AI æ­£åœ¨ä¸ºæ‚¨è§£æä¹¦ç±æ ¸å¿ƒæ´å¯Ÿ...")
    else:
        for book in data["books"]:
            with st.expander(f"ğŸ“– {book['book_title']}", expanded=True):
                st.subheader("ç¬¬ä¸€æ€§åŸç† (First Principle)")
                st.write(book['first_principle'])
                st.subheader("æˆ˜ç•¥æ´å¯Ÿ (Executive Insights)")
                for insight in book['insights']:
                    st.markdown(f"- {insight}")
                st.success(f"ğŸ™ï¸ **é«˜ç®¡è¡¨è¾¾è¯æœ¯:** {book['executive_phrasing']}")

# --- é¢‘é“ 3: æ€ç»´æ¨¡å‹ (é¢„ç½® 10 ä¸ª) ---
elif menu == "ğŸ§  æ€ç»´æ¨¡å‹":
    st.header("ğŸ§  å•†ä¸šæ€ç»´æ¨¡å‹åº“ (Top 10)")
    models = {
        "1. ç¬¬ä¸€æ€§åŸç†": "æ‹†è§£äº‹ç‰©è‡³ç‰©ç†æœ¬è´¨ï¼Œé‡æ–°æ„å»ºã€‚",
        "2. ç¬¬äºŒæ›²çº¿": "åœ¨ç°æœ‰ä¸šåŠ¡è¾¾åˆ°é¡¶å³°å‰å¼€å¯æ–°å¢é•¿ç‚¹ã€‚",
        "3. é£è½®æ•ˆåº”": "å»ºç«‹è‰¯æ€§å¾ªç¯ï¼Œè®©ä¸šåŠ¡è‡ªåŠ¨åŠ é€Ÿã€‚",
        "4. è¾¹é™…å®‰å…¨": "ä¸ºå†³ç­–é¢„ç•™å®¹é”™ç©ºé—´ï¼Œé˜²æ­¢ç³»ç»Ÿå´©ç›˜ã€‚",
        "5. å¸•ç´¯æ‰˜æ³•åˆ™": "èšç„¦å†³å®š 80% äº§å‡ºçš„ 20% æ ¸å¿ƒæŠ•å…¥ã€‚",
        "6. å¤åˆ©æ•ˆåº”": "é€šè¿‡å¾®å°ä¸”æŒç»­çš„è¿­ä»£å®ç°æŒ‡æ•°çº§å¢é•¿ã€‚",
        "7. æœºä¼šæˆæœ¬": "è¡¡é‡æ”¾å¼ƒæœ€é«˜ä»·å€¼æ›¿ä»£æ–¹æ¡ˆçš„ä»£ä»·ã€‚",
        "8. åè„†å¼±": "ä»å‹åŠ›ã€æ³¢åŠ¨å’Œéšæœºæ€§ä¸­è·ç›Šã€‚",
        "9. èƒœä»»åŠ›åœˆ": "ä¸“æ³¨äºè‡ªå·±çœŸæ­£ç†è§£å¹¶æ“…é•¿çš„é¢†åŸŸã€‚",
        "10. æ²‰æ²¡æˆæœ¬è¯¯åŒº": "ç†æ€§å†³ç­–åº”å…³æ³¨æœªæ¥ï¼Œè€Œéå·²æ— æ³•æ”¶å›çš„æˆæœ¬ã€‚"
    }
    col1, col2 = st.columns(2)
    for i, (m_name, m_desc) in enumerate(models.items()):
        target = col1 if i % 2 == 0 else col2
        with target.expander(m_name):
            st.write(m_desc)
            # ä¿®å¤ä¹‹å‰çš„ç¼©è¿›é”™è¯¯ï¼šç¡®ä¿ if å—å†…æœ‰å†…å®¹
            if "é£è½®æ•ˆåº”" in m_name:
                st.write("ğŸ“ˆ *åº”ç”¨å»ºè®®ï¼šå¯»æ‰¾ä¼ä¸šä¸­èƒ½å¤Ÿäº’ç›¸æ¨åŠ¨çš„é—­ç¯å› ç´ ã€‚*")
                
# --- é¢‘é“ 4: è‹±æ–‡æ•™ç»ƒ (å½»åº•ä¿®å¤æ‹¥æŒ¤) ---
elif menu == "ğŸ™ï¸ è‹±æ–‡æ•™ç»ƒ":
    st.header("ğŸ™ï¸ è‹±æ–‡æ•™ç»ƒï¼šé«˜é˜¶è¡¨è¾¾å¡ç‰‡")
    if data.get("articles"):
        all_vocab = {}
        for a in data["articles"]: all_vocab.update(a.get('vocabulary', {}))
        
        # å¼ºåˆ¶ä¸¤åˆ—å‚ç›´æ’åˆ—ï¼Œè§£å†³æˆªå›¾ 2 çš„æ‹¥æŒ¤æ„Ÿ
        v_col1, v_col2 = st.columns(2)
        for i, (word, mean) in enumerate(all_vocab.items()):
            target = v_col1 if i % 2 == 0 else v_col2
            target.markdown(f'<div class="vocab-card"><strong>{word}</strong><br><small>{mean}</small></div>', unsafe_allow_html=True)
