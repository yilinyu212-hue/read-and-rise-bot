import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime

# 1. é¡µé¢åŸºæœ¬é…ç½®
st.set_page_config(page_title="Read & Rise | AI Business Coach", layout="wide", page_icon="ğŸ¹")

# 2. æ³¨å…¥ä¸“ä¸šè§†è§‰æ ·å¼
st.markdown("""
    <style>
    .welcome-text { font-size: 3rem; font-weight: 800; color: #10416F; margin-bottom: 0; }
    .leader-card {
        background: white; padding: 25px; border-radius: 12px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05); border-left: 8px solid #10416F; margin-bottom: 20px;
    }
    .en-term { color: #10416F; font-weight: bold; background: #eef2f6; padding: 2px 6px; border-radius: 4px; }
    </style>
""", unsafe_allow_html=True)

# 3. æ•°æ®åŠ è½½é€»è¾‘ (å¢åŠ å…¼å®¹æ€§å¤„ç†)
def load_data():
    if os.path.exists("data.json"):
        try:
            with open("data.json", "r", encoding="utf-8") as f:
                data = json.load(f)
                return data if isinstance(data, list) else []
        except: return []
    return []

articles = load_data()

# 4. ä¾§è¾¹æ å¯¼èˆª
with st.sidebar:
    st.markdown("<h1 style='color: #10416F;'>ğŸ¹ Read & Rise</h1>", unsafe_allow_html=True)
    st.caption("AI Business Coach & English Mentor")
    st.divider()
    menu = st.radio("å¯¼èˆª (Navigation)", ["ğŸš€ ä»Šæ—¥å†…å‚ Briefing", "ğŸ§  æ€ç»´æ¨¡å‹ Library", "ğŸ™ï¸ è‹±æ–‡æ•™ç»ƒ Coaching"])
    st.divider()
    st.info("ğŸ’¡ **Coach Note**: å“è¶Šçš„é¢†å¯¼è€…ä¸ä»…é˜…è¯»èµ„è®¯ï¼Œæ›´åœ¨æ„å»ºè®¤çŸ¥æ¡†æ¶ã€‚")

# --- é¢‘é“ 1: ä»Šæ—¥å†…å‚ ---
if menu == "ğŸš€ ä»Šæ—¥å†…å‚ Briefing":
    st.markdown('<p class="welcome-text">Hi, Leaders!</p>', unsafe_allow_html=True)
    st.write(f"ğŸ“… Sync Date: {datetime.now().strftime('%Y-%m-%d')} | Global Insight")
    
    if not articles:
        st.info("ğŸ”„ **æ­£åœ¨åŒæ­¥å…¨çƒæœ€æ–°å†…å‚...**\n\næ•°æ®æ­£åœ¨ä» HBR å’Œ McKinsey å®æ—¶åŒæ­¥å¹¶ç”± AI æ‹†è§£ä¸­ã€‚æ‚¨å¯ä»¥å…ˆå» **â€˜æ€ç»´æ¨¡å‹â€™** é¢‘é“æŸ¥çœ‹å·²ä¸ºæ‚¨å‡†å¤‡å¥½çš„åº•å±‚é€»è¾‘ã€‚")
    else:
        for art in articles:
            with st.container():
                st.markdown(f'<div class="leader-card"><h3>{art.get("title")}</h3><p style="color:gray;">{art.get("source")}</p></div>', unsafe_allow_html=True)
                t1, t2 = st.tabs(["ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ·±åº¦æ‹†è§£", "ğŸ‡¬ğŸ‡§ English Summary"])
                with t1:
                    st.markdown(art.get('cn_analysis') or art.get('content', 'è§£æä¸­...'))
                    st.link_button("ğŸŒ é˜…è¯»åŸæ–‡", art.get('link'))
                with t2:
                    st.write(art.get('en_summary', 'Summarizing in progress...'))

# --- é¢‘é“ 2: æ€ç»´æ¨¡å‹ (å†…ç½®å¸¸é©»å†…å®¹) ---
elif menu == "ğŸ§  æ€ç»´æ¨¡å‹ Library":
    st.header("ğŸ§  å•†ä¸šæ€ç»´æ¨¡å‹åº“ (Mental Models)")
    st.write("è¿™äº›æ¨¡å‹æ˜¯æ‚¨å†³ç­–çš„â€œåº•å±‚æ“ä½œç³»ç»Ÿâ€ã€‚")
    
    m_col1, m_col2 = st.columns(2)
    
    with m_col1:
        with st.expander("ğŸ“ˆ ç¬¬äºŒæ›²çº¿ (The Second Curve)", expanded=True):
            st.markdown("åœ¨ç¬¬ä¸€æ›²çº¿åˆ°è¾¾å·…å³°å‰ï¼Œå¯åŠ¨æ–°å¢é•¿ç‚¹ã€‚")
            st.graphviz_chart('''
                digraph { node[fontname="SimHei",shape=box,color="#10416F"] 
                "åˆ›æ–°ç‚¹" -> "ç¬¬äºŒæ›²çº¿(æŠ•å…¥æœŸ)" -> "æŒ‡æ•°å¢é•¿"; "ç°æœ‰ä¸šåŠ¡" -> "å·…å³°æœŸ" -> "è¡°é€€æœŸ"; }
            ''')
            

    with m_col2:
        with st.expander("ğŸ”¬ ç¬¬ä¸€æ€§åŸç† (First Principles)", expanded=True):
            st.markdown("å‰¥ç¦»å‡è®¾ï¼Œå›å½’ç‰©ç†æœ¬è´¨é‡æ–°æ„å»ºã€‚")
            st.graphviz_chart('''
                digraph { node[fontname="SimHei",shape=ellipse,color="#2E7D32"] 
                "é—®é¢˜" -> "æ‹†è§£å‡è®¾" -> "åŸå­äº‹å®" -> "é‡æ–°æ¶æ„"; }
            ''')
            

# --- é¢‘é“ 3: è‹±æ–‡æ•™ç»ƒ (å†…ç½®å¸¸é©»å†…å®¹) ---
elif menu == "ğŸ™ï¸ è‹±æ–‡æ•™ç»ƒ Coaching":
    st.header("ğŸ™ï¸ é¢†å¯¼è€…è¡¨è¾¾æ•™ç»ƒ (Executive Phrasing)")
    
    st.subheader("ğŸ”¥ æ ¸å¿ƒæœ¯è¯­åº“")
    cols = st.columns(3)
    vocab_list = [
        ("Strategic Pivot", "æˆ˜ç•¥è½¬å‹"), ("Value Proposition", "ä»·å€¼ä¸»å¼ "),
        ("Leverage", "æ æ†ä½œç”¨"), ("Scalability", "å¯æ‰©å±•æ€§"),
        ("Bottleneck", "ç“¶é¢ˆ"), ("Synergy", "ååŒæ•ˆåº”")
    ]
    for i, (word, mean) in enumerate(vocab_list):
        cols[i % 3].markdown(f"<span class='en-term'>{word}</span><br>{mean}", unsafe_allow_html=True)
    
    st.divider()
    st.subheader("ğŸ’¬ ä¼šè®®å®æˆ˜è¯æœ¯")
    st.code("How to say 'è½¬å‹': \n'Given the market volatility, we need to execute a strategic pivot to stay competitive.'", language="text")
    st.code("How to say 'æ æ†': \n'We should leverage our existing network to accelerate user acquisition.'", language="text")
