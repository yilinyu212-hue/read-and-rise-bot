import requests
import feedparser
import json
import os
import time
from datetime import datetime

# ================= 1. é…ç½®ä¸­å¿ƒ =================
# è¯·ç¡®ä¿åœ¨ GitHub Secrets æˆ–ç¯å¢ƒå˜é‡ä¸­è®¾ç½®äº† DEEPSEEK_API_KEY
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# 10+ ä¸ªå…¨çƒé¡¶çº§æ™ºåº“æº
RSS_SOURCES = [
    {"name": "Harvard Business Review", "url": "https://hbr.org/rss/feed/topics/leadership"},
    {"name": "McKinsey Insights", "url": "https://www.mckinsey.com/insights/rss"},
    {"name": "BCG Global", "url": "https://www.bcg.com/rss.xml"},
    {"name": "The Economist", "url": "https://www.economist.com/business/rss.xml"},
    {"name": "Fortune", "url": "https://fortune.com/feed/"},
    {"name": "Knowledge@Wharton", "url": "https://knowledge.wharton.upenn.edu/feed/"},
    {"name": "Strategy+Business", "url": "https://www.strategy-business.com/rss/all_articles"},
    {"name": "MIT Tech Review", "url": "https://www.technologyreview.com/feed/"},
    {"name": "Fast Company", "url": "https://www.fastcompany.com/latest/rss"},
    {"name": "Wired Business", "url": "https://www.wired.com/feed/category/business/latest/rss"}
]

# ================= 2. AI æ·±åº¦è§£æå¼•æ“ =================
def ai_deep_analyze(title, link):
    url = "https://api.deepseek.com/chat/completions"
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # å¼ºåˆ¶è¦æ±‚ AI äº§å‡ºä¸­è‹±åŒè¯­åŠæ·±åº¦å†…å®¹
    prompt = f"""
    You are the Chief AI Coach for 'Read & Rise'. Deeply analyze the business article: "{title}".
    
    Return a strictly valid JSON object with the following fields:
    1. "en_summary": 3 bullet points summary in English.
    2. "cn_summary": 3æ¡æ ¸å¿ƒä¸­æ–‡æ‘˜è¦ï¼ˆæ·±åº¦æ´å¯Ÿï¼‰.
    3. "golden_sentences": [{{ "en": "quote", "cn": "å¯¹åº”ä¸­æ–‡é‡‘å¥" }}] (Extract 2 sentences).
    4. "vocab_bank": [{{ "word": "term", "meaning": "ä¸­æ–‡å«ä¹‰", "example": "English example sentence" }}] (Extract 3 professional terms).
    5. "case_study": "ä¸­è‹±åŒè¯­è§£æï¼šèƒŒæ™¯-æŒ‘æˆ˜-å†³ç­–-ç»“æœ (Background-Challenge-Decision-Result)".
    6. "reflection_flow": ["é—®é¢˜1: å…³äºå¸ƒå±€", "é—®é¢˜2: å…³äºè§„åˆ’", "é—®é¢˜3: å®è·µå»ºè®®"].
    7. "related_model": "The most relevant mental model (e.g., First Principles, Anti-fragile)".
    8. "scores": {{ "Strategy": 85, "Insight": 90, "Leadership": 80, "Innovation": 75, "Decision": 85 }}
    """
    
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "You are a professional executive coach with a McKinsey background. You provide high-density, actionable insights."},
            {"role": "user", "content": prompt}
        ],
        "response_format": {"type": "json_object"},
        "temperature": 0.3
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        res_json = response.json()
        analysis = json.loads(res_json['choices'][0]['message']['content'])
        
        # è¡¥å……åŸºç¡€ä¿¡æ¯
        analysis["title"] = title
        analysis["link"] = link
        analysis["sync_date"] = datetime.now().strftime("%Y-%m-%d")
        return analysis
    except Exception as e:
        print(f"âŒ Error analyzing {title}: {e}")
        return None

# ================= 3. ä¸»è¿è¡Œé€»è¾‘ =================
def run_sync():
    print(f"ğŸš€ [{datetime.now()}] Starting Global Insight Sync...")
    
    # åˆå§‹åŒ–æ•°æ®ç»“æ„
    data = {
        "briefs": [], 
        "deep_articles": [], 
        "weekly_question": {
            "cn": "é¢å¯¹å‰§å˜çš„ 2026ï¼Œä½ çš„ä¼ä¸šå¸ƒå±€æ˜¯å¦å…·å¤‡â€˜åè„†å¼±â€™ç‰¹å¾ï¼Ÿ", 
            "en": "In a volatile 2026, does your business layout possess 'anti-fragile' characteristics?"
        },
        "update_time": datetime.now().strftime("%Y-%m-%d %H:%M")
    }

    # å¦‚æœå­˜åœ¨æ—§æ•°æ®ï¼Œè¯»å–å®ƒä»¥ä¿ç•™æ‰‹åŠ¨ä¸Šä¼ çš„ deep_articles
    if os.path.exists("data.json"):
        try:
            with open("data.json", "r", encoding="utf-8") as f:
                old_data = json.load(f)
                data["deep_articles"] = old_data.get("deep_articles", [])
                data["weekly_question"] = old_data.get("weekly_question", data["weekly_question"])
        except Exception as e:
            print(f"âš ï¸ Could not read old data.json: {e}")

    # éå†æŠ“å– 10+ æº
    for source in RSS_SOURCES:
        print(f"ğŸ“¡ Scanning: {source['name']}...")
        try:
            feed = feedparser.parse(source['url'])
            if not feed.entries:
                continue
            
            # æ¯æ¬¡åªå–æ¯ä¸ªæºæœ€æ–°çš„ä¸€ç¯‡ï¼Œä¿è¯è´¨é‡å’Œ API é¢åº¦
            latest_entry = feed.entries[0]
            
            # AI è§£æ
            analysis = ai_deep_analyze(latest_entry.title, latest_entry.link)
            if analysis:
                analysis["source"] = source['name']
                data["briefs"].append(analysis)
                print(f"âœ… Success: {latest_entry.title}")
            
            # ç¨å¾®åœé¡¿ï¼Œé¿å…è¯·æ±‚è¿‡å¿«è¢«å°æˆ– API é¢‘ç‡é™åˆ¶
            time.sleep(1)
            
        except Exception as e:
            print(f"âŒ Failed to sync {source['name']}: {e}")

    # ä¿å­˜ç»“æœ
    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    
    print(f"ğŸ [{datetime.now()}] All sync tasks completed.")

if __name__ == "__main__":
    # ç¡®ä¿ API KEY å­˜åœ¨
    if not DEEPSEEK_API_KEY:
        print("âŒ ERROR: DEEPSEEK_API_KEY not found in environment variables.")
    else:
        run_sync()
