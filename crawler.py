import requests
import feedparser
import json
import os
import time
from datetime import datetime

# ================= 1. ç¯å¢ƒé…ç½® =================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# 12 ä¸ªé¡¶çº§å•†ä¸šä¸ç§‘æŠ€æº
RSS_SOURCES = [
    {"name": "Harvard Business Review", "url": "https://hbr.org/rss/feed/topics/leadership"},
    {"name": "McKinsey Insights", "url": "https://www.mckinsey.com/insights/rss"},
    {"name": "BCG Global", "url": "https://www.bcg.com/rss.xml"},
    {"name": "The Economist", "url": "https://www.economist.com/business/rss.xml"},
    {"name": "MIT Technology Review", "url": "https://www.technologyreview.com/feed/"},
    {"name": "Financial Times", "url": "https://www.ft.com/management?format=rss"},
    {"name": "Strategy+Business", "url": "https://www.strategy-business.com/rss/all_articles"},
    {"name": "Knowledge at Wharton", "url": "https://knowledge.wharton.upenn.edu/feed/"},
    {"name": "Fast Company", "url": "https://www.fastcompany.com/latest/rss"},
    {"name": "Wired Business", "url": "https://www.wired.com/feed/category/business/latest/rss"},
    {"name": "Fortune", "url": "https://fortune.com/feed/"},
    {"name": "TechCrunch", "url": "https://techcrunch.com/category/enterprise/feed/"}
]

# AI ç²¾è¯»ä¹¦ç±æ¸…å•
BOOKS_TO_READ = [
    "ã€ŠThe Second Curveã€‹- Charles Handy",
    "ã€ŠPrinciplesã€‹- Ray Dalio",
    "ã€ŠHigh Output Managementã€‹- Andrew Grove",
    "ã€ŠZero to Oneã€‹- Peter Thiel",
    "ã€ŠBuilt to Lastã€‹- Jim Collins"
]

# ================= 2. AI è§£æå¼•æ“ =================
def ai_call(prompt):
    url = "https://api.deepseek.com/chat/completions"
    headers = {"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"}
    try:
        data = {"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}], "temperature": 0.3}
        response = requests.post(url, headers=headers, json=data, timeout=60)
        content = response.json()['choices'][0]['message']['content'].strip()
        # å¼ºæ•ˆæ¸…æ´— Markdown æ ‡ç­¾
        if "```" in content:
            content = content.split("```")[1].replace("json", "").strip()
        return json.loads(content)
    except Exception as e:
        print(f"AI Error: {e}")
        return None

def analyze_article(title, source):
    prompt = f"Analyze article '{title}' from {source}. Output JSON: {{'en_summary': '3 executive points', 'cn_analysis': '### ğŸ§  æ€ç»´æ¨¡å‹\\n...\\n\\n### ğŸ› ï¸ å†³ç­–å»ºè®®\\n...', 'scores': {{'æˆ˜ç•¥æ€ç»´': 85, 'ç»„ç»‡è¿›åŒ–': 80, 'å†³ç­–éŸ§æ€§': 75, 'è¡Œä¸šæ´å¯Ÿ': 90, 'æŠ€æœ¯è§†é‡': 70}}, 'vocabulary': {{'Term': 'Chinese Meaning'}}}}"
    return ai_call(prompt)

def analyze_book(book_name):
    prompt = f"Provide a deep executive summary for '{book_name}'. Output JSON: {{'book_title': '{book_name}', 'first_principle': 'Core logic', 'insights': ['Insight 1', 'Insight 2', 'Insight 3'], 'executive_phrasing': 'One English sentence for meetings'}}"
    return ai_call(prompt)

# ================= 3. ä¸»æµç¨‹ =================
def run_sync():
    final_data = {"articles": [], "books": []}
    
    print("ğŸ“¡ åŒæ­¥ 12 ä¸ªå¤–åˆŠæº...")
    for source in RSS_SOURCES:
        try:
            feed = feedparser.parse(source['url'])
            for item in feed.entries[:1]:
                res = analyze_article(item.title, source['name'])
                if res:
                    res.update({"title": item.title, "link": item.link, "source": source['name']})
                    final_data["articles"].append(res)
            time.sleep(1)
        except: continue

    print("ğŸ“š ç”Ÿæˆä¹¦ç±ç²¾è¯»ç¬”è®°...")
    for book in BOOKS_TO_READ:
        res = analyze_book(book)
        if res: final_data["books"].append(res)
        time.sleep(1)

    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(final_data, f, ensure_ascii=False, indent=4)
    print("âœ… å…¨åº“åŒæ­¥å®Œæˆ")

if __name__ == "__main__":
    run_sync()
