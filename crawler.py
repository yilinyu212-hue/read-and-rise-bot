import requests
import feedparser
import json
import os
import time
from datetime import datetime

# ================= é…ç½®åŒº =================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# 12 ä¸ªé¡¶çº§å•†ä¸šä¸ç§‘æŠ€æº
RSS_SOURCES = [
    # --- ç»¼åˆæˆ˜ç•¥ä¸ç®¡ç† ---
    {"name": "Harvard Business Review", "url": "https://hbr.org/rss/feed/topics/leadership"},
    {"name": "McKinsey Insights", "url": "https://www.mckinsey.com/insights/rss"},
    {"name": "BCG Global", "url": "https://www.bcg.com/rss.xml"},
    {"name": "Knowledge at Wharton", "url": "https://knowledge.wharton.upenn.edu/feed/"},
    
    # --- ç§‘æŠ€ä¸æ•°å­—è½¬å‹ ---
    {"name": "MIT Technology Review", "url": "https://www.technologyreview.com/feed/"},
    {"name": "Wired Business", "url": "https://www.wired.com/feed/category/business/latest/rss"},
    {"name": "TechCrunch Enterprise", "url": "https://techcrunch.com/category/enterprise/feed/"},
    
    # --- é‡‘èä¸å…¨çƒå®è§‚ ---
    {"name": "The Economist", "url": "https://www.economist.com/business/rss.xml"},
    {"name": "Financial Times - Management", "url": "https://www.ft.com/management?format=rss"},
    {"name": "Reuters Business", "url": "http://feeds.reuters.com/reuters/businessNews"},
    
    # --- åˆ›æ–°ä¸è®¾è®¡æ€ç»´ ---
    {"name": "Fast Company", "url": "https://www.fastcompany.com/latest/rss"},
    {"name": "Strategy+Business", "url": "https://www.strategy-business.com/rss/all_articles"}
]

def ai_analyze(title, source_name):
    """
    AI æ•™ç»ƒåŒè¯­æ‹†è§£é€»è¾‘ (å¢åŠ äº†é‡è¯•æœºåˆ¶ï¼Œé˜²æ­¢ API æŠ–åŠ¨)
    """
    url = "https://api.deepseek.com/chat/completions"
    headers = {"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"}
    
    prompt = f"""
    You are a world-class AI Business Coach. Analyze article "{title}" from {source_name}.
    Output strictly in JSON:
    {{
      "en_summary": "3 executive bullet points.",
      "cn_analysis": "### ğŸ§  æ€ç»´æ¨¡å‹\\n...\\n\\n### ğŸ› ï¸ å†³ç­–å»ºè®®\\n...",
      "scores": {{"æˆ˜ç•¥æ€ç»´": 80, "ç»„ç»‡è¿›åŒ–": 80, "å†³ç­–éŸ§æ€§": 80, "è¡Œä¸šæ´å¯Ÿ": 80, "æŠ€æœ¯è§†é‡": 80}},
      "vocabulary": {{"Term": "Meaning"}}
    }}
    """
    
    try:
        data = {"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}], "temperature": 0.3}
        response = requests.post(url, headers=headers, json=data, timeout=60)
        res = response.json()
        content = res['choices'][0]['message']['content'].strip()
        # è‡ªåŠ¨å‰”é™¤ ```json æ ‡è®°
        if "```" in content: content = content.split("```")[1].replace("json", "").strip()
        return json.loads(content)
    except:
        return None

def run_sync():
    all_articles = []
    print(f"ğŸš€ å¼€å§‹å…¨é‡åŒæ­¥ï¼Œå…±è®¡ {len(RSS_SOURCES)} ä¸ªæº...")
    
    for source in RSS_SOURCES:
        try:
            print(f"ğŸ“¡ æŠ“å–ä¸­: {source['name']}...")
            feed = feedparser.parse(source['url'])
            # æ¯ä¸ªæºåªå–æœ€æ–° 1 ç¯‡ï¼Œ12ä¸ªæºä¿è¯äº†å¤šæ ·æ€§åŒæ—¶èŠ‚çœ API é¢åº¦
            for item in feed.entries[:1]:
                analysis = ai_analyze(item.title, source['name'])
                if analysis:
                    all_articles.append({
                        "title": item.title, "link": item.link, "source": source['name'],
                        "date": datetime.now().strftime("%Y-%m-%d"),
                        **analysis
                    })
                time.sleep(1) 
        except Exception as e:
            print(f"âŒ {source['name']} å¤±è´¥: {e}")

    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(all_articles, f, ensure_ascii=False, indent=4)
    print(f"âœ… åŒæ­¥å®Œæˆï¼Œä»Šæ—¥å…±è·å– {len(all_articles)} ç¯‡æ·±åº¦å†…å‚ã€‚")

if __name__ == "__main__":
    run_sync()
