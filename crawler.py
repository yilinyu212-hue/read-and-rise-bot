import requests, feedparser, json, os, asyncio, edge_tts
from datetime import datetime

DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

RSS_SOURCES = [
    {"name": "McKinsey", "url": "https://www.mckinsey.com/insights/rss"},
    {"name": "HBR", "url": "https://hbr.org/rss/feed/topics/leadership"},
    {"name": "Economist", "url": "https://www.economist.com/business/rss.xml"},
    {"name": "MIT Tech Review", "url": "https://www.technologyreview.com/feed/"}
]

def ai_analyze(title, link):
    if not DEEPSEEK_API_KEY: return None
    url = "https://api.deepseek.com/chat/completions"
    
    # å¼ºåˆ¶æ ‡ç­¾åŒ–ä¸ä¸­è‹±åŒè¯­
    prompt = f"""ä½œä¸ºä¼ä¸šå®¶é¡¾é—®ï¼Œè§£ææ–‡ç« : '{title}'ã€‚
    å¿…é¡»è¿”å›å¦‚ä¸‹ä¸¥æ ¼JSONæ ¼å¼(åŒå¤§æ‹¬å·è½¬ä¹‰):
    {{{{
        "en_summary": "150-word English executive summary.",
        "cn_analysis": "300å­—ä¸­æ–‡æ·±åº¦æ‹†è§£(åŒ…å«æˆ˜ç•¥/åˆ›æ–°/æ‰§è¡Œç»´åº¦)ã€‚",
        "reading_level": "Level: Strategic (é«˜é˜¶)",
        "tags": ["AI", "Management", "Global"],
        "reflection_flow": ["é—®é¢˜1: ...", "é—®é¢˜2: ..."],
        "action_points": ["å»ºè®®1: ...", "å»ºè®®2: ..."],
        "model_scores": {{"æˆ˜ç•¥": 90, "åˆ›æ–°": 85, "æ‰§è¡Œ": 70}}
    }}}}"""
    
    try:
        res = requests.post(url, headers={"Authorization": f"Bearer {DEEPSEEK_API_KEY}"}, json={
            "model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}],
            "response_format": {"type": "json_object"}, "temperature": 0.3
        }, timeout=60)
        content = json.loads(res.json()['choices'][0]['message']['content'])
        content.update({"title": title, "link": link})
        return content
    except: return None

async def generate_audio(text):
    # ç”Ÿæˆç£æ€§ç”·å£°ä¼¦æ•¦è…”
    communicate = edge_tts.Communicate(text, "en-GB-RyanNeural")
    await communicate.save("daily_briefing.mp3")

def run_sync():
    print("ğŸš€ Read & Rise æ•°æ®ä¸­æ¢è¿è¡Œä¸­...")
    books = []
    if os.path.exists("data.json"):
        try:
            with open("data.json", "r", encoding="utf-8") as f:
                books = json.load(f).get("books", [])
        except: pass

    data = {"briefs": [], "books": books, "update_time": datetime.now().strftime("%Y-%m-%d %H:%M")}
    
    for s in RSS_SOURCES:
        feed = feedparser.parse(s['url'])
        if feed.entries:
            res = ai_analyze(feed.entries[0].title, feed.entries[0].link)
            if res:
                res["source"] = s['name']
                data["briefs"].append(res)
    
    if data["briefs"]:
        script = "Hi Leaders! Welcome to Read and Rise. Today we have top insights from McKinsey and HBR. Let's start."
        asyncio.run(generate_audio(script))

    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

if __name__ == "__main__":
    run_sync()
