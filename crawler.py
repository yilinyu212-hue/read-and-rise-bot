import requests, feedparser, json, os, time
from datetime import datetime

# ================= 1. é…ç½®ä¸­å¿ƒ =================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

RSS_SOURCES = [
    {"name": "McKinsey", "url": "https://www.mckinsey.com/insights/rss"},
    {"name": "HBR", "url": "https://hbr.org/rss/feed/topics/leadership"},
    {"name": "Economist", "url": "https://www.economist.com/business/rss.xml"},
    {"name": "Fortune", "url": "https://fortune.com/feed/"}
]

# ================= 2. AI è§£æå¼•æ“ =================
def ai_deep_analyze(title, link):
    url = "https://api.deepseek.com/chat/completions"
    prompt = f"""è§£ææ–‡ç« : "{title}"ã€‚å¿…é¡»è¿”å›ä¸¥æ ¼JSONæ ¼å¼ï¼š
    {{
        "en_summary": ["English Point 1", "Point 2"],
        "cn_summary": ["ä¸­æ–‡è¦ç‚¹1", "è¦ç‚¹2"],
        "golden_sentences": [{{"en":"quote", "cn":"é‡‘å¥"}}],
        "vocab_bank": [{{"word":"Term", "meaning":"å«ä¹‰", "example":"Example"}}],
        "case_study": "èƒŒæ™¯-å†³ç­–-ç»“æœè§£æ",
        "reflection_flow": ["åæ€1", "åæ€2"],
        "related_model": "æ€ç»´æ¨¡å‹åç§°"
    }}"""
    
    try:
        res = requests.post(url, headers={"Authorization": f"Bearer {DEEPSEEK_API_KEY}"}, json={
            "model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}],
            "response_format": {"type": "json_object"}, "temperature": 0.3
        }, timeout=60)
        content = json.loads(res.json()['choices'][0]['message']['content'])
        content.update({"title": title, "link": link})
        return content
    except: return None

# ================= 3. ä¸»ç¨‹åº =================
def run_sync():
    print(f"ğŸš€ å¼€å§‹æ‰«æå…¨çƒæ™ºåº“...")
    data = {
        "briefs": [], 
        "weekly_question": {
            "cn": "é¢å¯¹ 2026 çš„æŒ‘æˆ˜ï¼Œå¦‚ä½•é€šè¿‡â€˜ç¬¬ä¸€æ€§åŸç†â€™é‡æ„æ ¸å¿ƒç«äº‰åŠ›ï¼Ÿ", 
            "en": "How to leverage First Principles to rebuild competitiveness?"
        },
        "update_time": datetime.now().strftime("%Y-%m-%d %H:%M")
    }

    for s in RSS_SOURCES:
        feed = feedparser.parse(s['url'])
        if feed.entries:
            res = ai_deep_analyze(feed.entries[0].title, feed.entries[0].link)
            if res:
                res["source"] = s['name']
                data["briefs"].append(res)
                print(f"âœ… è§£ææˆåŠŸ: {s['name']}")

    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    print("ğŸ å…¨éƒ¨åŒæ­¥å®Œæˆï¼")

if __name__ == "__main__":
    run_sync()
