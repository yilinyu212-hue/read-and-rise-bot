import requests
import feedparser
import json
import os
import time

# ä»ç¯å¢ƒå˜é‡è·å–å¯†é’¥ï¼ˆGitHub Actions ä¼šè‡ªåŠ¨æ³¨å…¥ï¼‰
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
FEISHU_APP_ID = os.getenv("FEISHU_APP_ID")
FEISHU_APP_SECRET = os.getenv("FEISHU_APP_SECRET")
APP_TOKEN = os.getenv("APP_TOKEN")
TABLE_ID = os.getenv("TABLE_ID")

# è®¢é˜…æºåˆ—è¡¨ï¼šèšç„¦å…¨çƒé¡¶å°–å•†ä¸šæ´å¯Ÿ
RSS_SOURCES = [
    {"name": "Harvard Business Review", "url": "https://hbr.org/rss/feed/topics/leadership"},
    {"name": "McKinsey Insights", "url": "https://www.mckinsey.com/insights/rss"},
    {"name": "Economist - Business", "url": "https://www.economist.com/business/rss.xml"}
]

def ai_analyze(title, source_name):
    """
    è°ƒç”¨ DeepSeek æ‰®æ¼” AI Business Coach è¿›è¡Œæ·±åº¦æ‹†è§£
    """
    print(f"ğŸ¤– AI Coach æ­£åœ¨æ·±åº¦æ‹†è§£: ã€Š{title}ã€‹...")
    url = "https://api.deepseek.com/chat/completions"
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½é¡¶å°–çš„ AI Business Coachã€‚è¯·é’ˆå¯¹æ–‡ç« ã€Š{title}ã€‹(æ¥æº:{source_name}) è¿›è¡Œå…¨æ–¹ä½çš„å•†ä¸šæ‹†è§£ã€‚
    è¯·åŠ¡å¿…ç«™åœ¨å„è¡Œå„ä¸š Leaders çš„é«˜åº¦ï¼ŒæŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„Markdownæ ¼å¼æ ‡è®°ï¼ˆå¦‚ ```json ï¼‰ï¼š

    {{
      "analysis": "### ğŸ§  æ€ç»´æ¨¡å‹\\nè¿™é‡Œå¡«å†™æ€ç»´æ¨¡å‹åº”ç”¨...\\n\\n### ğŸ“š å…³è”ä¹¦ç±\\næ¨èä¹¦ç±åŠæ ¸å¿ƒè§‚ç‚¹...\\n\\n### ğŸ› ï¸ å†³ç­–å‚è€ƒ\\næˆ˜ç•¥åˆ¤æ–­ä¸é¿å‘æŒ‡å—...",
      "scores": {{
        "æˆ˜ç•¥æ€ç»´": 85,
        "ç»„ç»‡è¿›åŒ–": 75,
        "å†³ç­–éŸ§æ€§": 70,
        "è¡Œä¸šæ´å¯Ÿ": 90,
        "æŠ€æœ¯è§†é‡": 80
      }}
    }}
    
    æ³¨æ„ï¼šanalysis å­—æ®µä¸­ä½¿ç”¨ \\n è¿›è¡Œæ¢è¡Œã€‚è¯„åˆ†å¿…é¡»åœ¨ 0-100 ä¹‹é—´ã€‚
    """
    
    try:
        data = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3
        }
        response = requests.post(url, headers=headers, json=data, timeout=60)
        res_json = response.json()
        content_raw = res_json['choices'][0]['message']['content'].strip()
        
        # å°è¯•è§£æ JSON å­—ç¬¦ä¸²
        return json.loads(content_raw)
    except Exception as e:
        print(f"âŒ AI è§£æå‡ºé”™: {e}")
        # è¿”å›é»˜è®¤ç»“æ„ï¼Œé˜²æ­¢ç¨‹åºå´©æºƒ
        return {
            "analysis": "### âš ï¸ è§£ææš‚æ—¶ä¸å¯ç”¨\næ•™ç»ƒæ­£åœ¨æ·±åº¦æ€è€ƒä¸­ï¼Œè¯·ç¨åå†è¯•ã€‚",
            "scores": {"æˆ˜ç•¥æ€ç»´": 50, "ç»„ç»‡è¿›åŒ–": 50, "å†³ç­–éŸ§æ€§": 50, "è¡Œä¸šæ´å¯Ÿ": 50, "æŠ€æœ¯è§†é‡": 50}
        }

def run_sync():
    all_articles = []
    
    for source in RSS_SOURCES:
        print(f"ğŸ“¡ æ­£åœ¨åŒæ­¥æº: {source['name']}...")
        feed = feedparser.parse(source['url'])
        
        # æ¯æ¬¡åªå–æ¯ä¸ªæºçš„å‰ 2 ç¯‡æœ€æ–°æ–‡ç« ï¼Œé¿å… AI é¢åº¦æ¶ˆè€—è¿‡å¿«
        for item in feed.entries[:2]:
            analysis_data = ai_analyze(item.title, source['name'])
            
            article = {
                "title": item.title,
                "link": item.link,
                "source": source['name'],
                "date": datetime.now().strftime("%Y-%m-%d"),
                "analysis": analysis_data.get("analysis"),
                "scores": analysis_data.get("scores")
            }
            all_articles.append(article)
            time.sleep(1) # ç¨ä½œåœé¡¿ï¼Œé¿å…è¯·æ±‚è¿‡å¿«

    # ä¿å­˜åˆ°æœ¬åœ° data.jsonï¼Œä¾›ç½‘é¡µè¯»å–
    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(all_articles, f, ensure_ascii=False, indent=4)
    print(f"âœ… ä»»åŠ¡å®Œæˆï¼Œå·²æˆåŠŸè§£æ {len(all_articles)} ç¯‡æ·±åº¦å†…å‚ã€‚")

if __name__ == "__main__":
    from datetime import datetime
    run_sync()
