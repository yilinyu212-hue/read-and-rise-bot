import os
import requests
import feedparser # éœ€è¦æ‰§è¡Œ pip install feedparser
from datetime import datetime

# --- é…ç½®åŒº ---
DEEPSEEK_KEY = "sk-500a770ac8e74c4cb38286ba27164c4a"
NOTION_TOKEN = "ntn_6058092242690eiABGM9YMvb0HPUXg9K40aFAfe1H59CV"
DATABASE_ID = "2e9e1ae7843a80ce8fe1f187a5adda68"

# ä½ æä¾›çš„ 10 ä¸ªå¤–åˆŠæº (RSS åœ°å€)
SOURCES = {
    "The Economist": "https://www.economist.com/finance-and-economics/rss.xml",
    "Harvard Business Review": "https://hbr.org/rss/topic/leadership",
    "The New York Times": "https://rss.nytimes.com/services/xml/rss/nyt/Education.xml",
    "MIT Sloan Management": "https://sloanreview.mit.edu/feed/",
    "McKinsey Insights": "https://www.mckinsey.com/insights/rss",
    "Fast Company": "https://www.fastcompany.com/leadership/rss",
    "Forbes Leadership": "https://www.forbes.com/leadership/feed/",
    "Wired": "https://www.wired.com/feed/category/business/latest/rss",
    "Nature (Science)": "https://www.nature.com/nature.rss",
    "Stanford News": "https://news.stanford.edu/feed/"
}

def fetch_rss_articles():
    """æ‰«ææ‰€æœ‰æºï¼ŒæŠ“å–æœ€æ–°æ–‡ç« æ ‡é¢˜"""
    new_articles = []
    for source_name, url in SOURCES.items():
        print(f"ğŸ“¡ æ­£åœ¨æ‰«æ {source_name}...")
        feed = feedparser.parse(url)
        for entry in feed.entries[:3]: # æ¯ä¸ªæºåªå–æœ€æ–°çš„3ç¯‡
            new_articles.append({
                "title": entry.title,
                "link": entry.link,
                "source": source_name
            })
    return new_articles

def create_notion_task(title, source, link):
    """æŠŠæŠ“å–åˆ°çš„æ–‡ç« å­˜å…¥ Notion å¾…å¤„ç†é˜Ÿåˆ—"""
    headers = {"Authorization": f"Bearer {NOTION_TOKEN}", "Content-Type": "application/json", "Notion-Version": "2022-06-28"}
    data = {
        "parent": {"database_id": DATABASE_ID},
        "properties": {
            "Name": {"title": [{"text": {"content": title}}]},
            "Category": {"select": {"name": "ğŸ“° Foreign Publication"}},
            "Status": {"select": {"name": "Pending"}},
            "Source_Link": {"url": link}
        }
    }
    requests.post("https://api.notion.com/v1/pages", headers=headers, json=data)

def run_auto_pipeline():
    # 1. æŠ“å–æ–‡ç« 
    articles = fetch_rss_articles()
    
    # 2. å­˜å…¥ Notion (è¿™é‡Œå¯ä»¥åŠ ä¸ªæŸ¥é‡é€»è¾‘ï¼Œé¿å…é‡å¤æŠ“å–)
    for art in articles:
        print(f"ğŸ“ æ­£åœ¨åŒæ­¥åˆ° Notion: {art['title']}")
        create_notion_task(art['title'], art['source'], art['link'])
    
    # 3. æ¥ä¸‹æ¥ä½ å¯ä»¥è¿è¡Œä¹‹å‰çš„ AI è§£æé€»è¾‘ï¼ŒæŠŠè¿™äº› Pending çš„æ–‡ç« å˜æˆåŠŸè¯¾
    print("ğŸš€ æŠ“å–å®Œæˆï¼ç°åœ¨ä½ å¯ä»¥è¿è¡Œ AI è§£æå™¨äº†ã€‚")

if __name__ == "__main__":
    run_auto_pipeline()
