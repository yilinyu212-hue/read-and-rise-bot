import os, feedparser, requests, json
from datetime import datetime

DEEPSEEK_KEY = os.environ.get("DEEPSEEK_API_KEY")

def get_coach_notes(title):
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {DEEPSEEK_KEY}"}
    prompt = f"""
    ä½œä¸ºç²¾è‹±ç®¡ç†æ•™ç»ƒï¼Œè¯·é’ˆå¯¹ã€Š{title}ã€‹åˆ¶ä½œè®²ä¹‰ã€‚
    è¯·æŒ‰ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºï¼š
    {{
      "tags": ["Leadership", "Strategy", "Tech", "Career", "Economy"], 
      "en_excerpt": "åŸæ–‡æ ¸å¿ƒæ®µè½ (50-80 words).",
      "cn_translation": "è¯¥æ®µè½çš„é«˜çº§å•†åŠ¡ä¸­æ–‡ç¿»è¯‘ã€‚",
      "vocabulary": "è¯æ±‡è§£æï¼š3ä¸ªé«˜é˜¶èŒåœºè¯æ±‡åŠå…¶åœ¨åœ°é“å•†ä¸šåœºæ™¯çš„åº”ç”¨ã€‚",
      "insight": "æ•™ç»ƒæ´å¯Ÿï¼šåˆ†ææœ¬æ–‡å¯¹ç®¡ç†è€…çš„å¯ç¤ºæˆ–å¯¹è¡Œä¸šçš„é¢„åˆ¤...",
      "action_task": "å®æˆ˜ä½œä¸šï¼šå»ºè®®çš„ä¸€é¡¹é’ˆå¯¹æ€§ç®¡ç†è¡ŒåŠ¨æˆ–è¡¨è¾¾ç»ƒä¹ ..."
    }}
    """
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "system", "content": "You are a world-class business English coach."}, {"role": "user", "content": prompt}],
        "response_format": {"type": "json_object"}
    }
    try:
        res = requests.post("https://api.deepseek.com/chat/completions", headers=headers, json=data, timeout=60)
        return res.json()['choices'][0]['message']['content']
    except:
        return json.dumps({"tags":["General"], "en_excerpt":"N/A", "cn_translation":"N/A", "vocabulary":"N/A", "insight":"N/A", "action_task":"N/A"})

def run():
    # --- æ‰©å……åçš„ 8 å¤§æ ¸å¿ƒä¿¡æº ---
    SOURCES = [
        {"name": "HBR (Leadership)", "url": "https://hbr.org/rss/topic/leadership"},
        {"name": "Economist (Briefing)", "url": "https://www.economist.com/briefing/rss.xml"},
        {"name": "WSJ (Business)", "url": "https://feeds.a.dj.com/rss/WSJBusiness.xml"},
        {"name": "Financial Times", "url": "https://www.ft.com/?format=rss"},
        {"name": "Fortune (Leadership)", "url": "https://fortune.com/category/leadership/feed/"},
        {"name": "MIT Tech Review", "url": "https://www.technologyreview.com/feed/"},
        {"name": "The Atlantic", "url": "https://www.theatlantic.com/feed/all/"},
        {"name": "Forbes (Innovation)", "url": "https://www.forbes.com/innovation/feed/"}
    ]
    
    UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    all_articles = []

    for src in SOURCES:
        try:
            print(f"ğŸŒ æ­£åœ¨è·å–: {src['name']}")
            resp = requests.get(src['url'], headers={"User-Agent": UA}, timeout=20)
            feed = feedparser.parse(resp.content)
            
            # æ¯ä¸ªæºå–æœ€æ–° 1 ç¯‡ï¼Œç¡®ä¿ 8 ç¯‡å†…å®¹å„ä¸ç›¸åŒï¼Œä¸”é™ä½å¤„ç†æ—¶é—´
            if feed.entries:
                entry = feed.entries[0]
                print(f"ğŸ“– æ­£åœ¨ç ”è¯»: {entry.title}")
                
                ai_data = json.loads(get_coach_notes(entry.title))
                all_articles.append({
                    "source": src['name'],
                    "title": entry.title,
                    "en_text": ai_data['en_excerpt'],
                    "cn_text": ai_data['cn_translation'],
                    "tags": ai_data['tags'],
                    "vocabulary": ai_data['vocabulary'],
                    "insight": ai_data['insight'],
                    "action": ai_data['action_task'],
                    "date": datetime.now().strftime("%Y-%m-%d"),
                    "link": entry.link
                })
        except Exception as e:
            print(f"âŒ {src['name']} è·å–å¤±è´¥: {e}")

    # ä¿å­˜æ•°æ®
    os.makedirs('data', exist_ok=True)
    with open('data/library.json', 'w', encoding='utf-8') as f:
        json.dump(all_articles, f, ensure_ascii=False, indent=4)
    print(f"âœ… æ•™ç ”åº“æ›´æ–°å®Œæˆï¼Œå…±è®¡ {len(all_articles)} ç¯‡æ·±åº¦æ•™æ¡ˆã€‚")

if __name__ == "__main__":
    run()
