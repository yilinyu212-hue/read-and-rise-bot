import requests
import feedparser
import json
import os
import time
from datetime import datetime

# ================= 1. é…ç½®ä¸­å¿ƒ =================
# å¿…é¡»åœ¨ GitHub Secrets ä¸­é…ç½® DEEPSEEK_API_KEY
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# 10ä¸ªç²¾é€‰å…¨çƒæ™ºåº“/å•†ä¸šæº
RSS_SOURCES = [
    {"name": "Harvard Business Review", "url": "https://hbr.org/rss/feed/topics/leadership"},
    {"name": "McKinsey Insights", "url": "https://www.mckinsey.com/insights/rss"},
    {"name": "BCG Global", "url": "https://www.bcg.com/rss.xml"},
    {"name": "The Economist", "url": "https://www.economist.com/business/rss.xml"},
    {"name": "Fortune", "url": "https://fortune.com/feed/"},
    {"name": "Knowledge@Wharton", "url": "https://knowledge.wharton.upenn.edu/feed/"},
    {"name": "Strategy+Business", "url": "https://www.strategy-business.com/rss/all_articles"},
    {"name": "MIT Tech Review", "url": "https://www.technologyreview.com/feed/"},
    {"name": "Fast Company", "url": "https://www.fastcompany.com/latest/rss"},
    {"name": "Wired Business", "url": "https://www.wired.com/feed/category/business/latest/rss"}
]

# ================= 2. AI æ·±åº¦è§£æå‡½æ•° =================
def ai_deep_analyze(title, link):
    if not DEEPSEEK_API_KEY:
        print("âŒ é”™è¯¯: æœªæ£€æµ‹åˆ° API KEY")
        return None

    url = "https://api.deepseek.com/chat/completions"
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # å¼ºåˆ¶ AI è¾“å‡ºæ ‡å‡†åˆ—è¡¨æ ¼å¼ï¼Œè§£å†³ app.py çš„ TypeError æŠ¥é”™
    prompt = f"""
    You are the Chief AI Coach for 'Read & Rise'. Deeply analyze the business article: "{title}".
    Return a STRICT JSON object with these fields:
    1. "en_summary": [3 key points in English as a LIST of strings]
    2. "cn_summary": [3æ¡æ ¸å¿ƒä¸­æ–‡æ‘˜è¦ï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰]
    3. "golden_sentences": [{{ "en": "quote", "cn": "å¯¹åº”ä¸­æ–‡é‡‘å¥" }}] (Extract 2)
    4. "vocab_bank": [{{ "word": "term", "meaning": "ä¸­æ–‡å«ä¹‰", "example": "English example" }}] (Extract 3)
    5. "case_study": "Deep analysis: Background-Challenge-Decision-Result"
    6. "reflection_flow": ["Question 1 about Layout", "Question 2 about Planning", "Question 3 Actionable Advice"]
    7. "related_model": "The most relevant mental model"
    8. "scores": {{ "Strategy": 85, "Insight": 90, "Leadership": 80, "Innovation": 75, "Decision": 85 }}
    """
    
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "You are a professional executive coach. Always output valid JSON."},
            {"role": "user", "content": prompt}
        ],
        "response_format": {"type": "json_object"},
        "temperature": 0.3
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        res_json = response.json()
        analysis = json.loads(res_json['choices'][0]['message']['content'])
        
        # è¡¥å…¨åŸºç¡€å­—æ®µ
        analysis["title"] = title
        analysis["link"] = link
        analysis["sync_date"] = datetime.now().strftime("%Y-%m-%d")
        return analysis
    except Exception as e:
        print(f"âŒ è§£ææ–‡ç« å¤±è´¥ {title}: {str(e)}")
        return None

# ================= 3. ä¸»è¿è¡Œç¨‹åº =================
def run_sync():
    print(f"ğŸ•’ [{datetime.now()}] å¯åŠ¨æ™ºåº“åŒæ­¥...")
    
    # åˆå§‹åŒ–æ•°æ®ç»“æ„ï¼ˆåŒ…å« weekly_questionï¼Œé˜²æ­¢ä¸»é¡µ KeyErrorï¼‰
    new_data = {
        "briefs": [], 
        "deep_articles": [], 
        "weekly_question": {
            "cn": "é¢å¯¹ 2026 çš„æŒ‘æˆ˜ï¼Œå¦‚ä½•é€šè¿‡â€˜ç¬¬ä¸€æ€§åŸç†â€™é‡æ„æ ¸å¿ƒç«äº‰åŠ›ï¼Ÿ", 
            "en": "How to leverage First Principles to rebuild competitiveness?"
        },
        "update_time": datetime.now().strftime("%Y-%m-%d %H:%M")
    }

    # å°è¯•è¯»å–æ—§æ•°æ®ä¸­çš„æ·±åº¦æ–‡ç« ï¼Œé¿å…è¢«è¦†ç›–
    if os.path.exists("data.json"):
        try:
            with open("data.json", "r", encoding="utf-8") as f:
                old_data = json.load(f)
                new_data["deep_articles"] = old_data.get("deep_articles", [])
                # å¦‚æœæ—§æ•°æ®æœ‰è‡ªå®šä¹‰é—®é¢˜ï¼Œå¯ä»¥ä¿ç•™
                new_data["weekly_question"] = old_data.get("weekly_question", new_data["weekly_question"])
        except:
            print("âš ï¸ æ—§ data.json æ ¼å¼æŸåï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")

    # éå† RSS æºæŠ“å–
    for source in RSS_SOURCES:
        print(f"ğŸ“¡ æ­£åœ¨æŠ“å–: {source['name']}...")
        try:
            feed = feedparser.parse(source['url'])
            if feed.entries:
                # è·å–è¯¥æºæœ€æ–°çš„ä¸€ç¯‡æ–‡ç« 
                latest = feed.entries[0]
                analysis = ai_deep_analyze(latest.title, latest.link)
                
                if analysis:
                    analysis["source"] = source['name']
                    new_data["briefs"].append(analysis)
                    print(f"âœ… æˆåŠŸè§£æ: {source['name']}")
                
                # é—´éš” 2 ç§’ï¼Œé˜²æ­¢ API é¢‘ç‡é™åˆ¶
                time.sleep(2)
        except Exception as e:
            print(f"âŒ æº {source['name']} æŠ“å–å¤±è´¥: {e}")

    # æœ€ç»ˆå†™å…¥æ–‡ä»¶
    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(new_data, f, ensure_ascii=False, indent=4)
    
    print(f"ğŸ åŒæ­¥å®Œæˆï¼å…±æŠ“å– {len(new_data['briefs'])} ç¯‡æ–°èµ„è®¯ã€‚")

if __name__ == "__main__":
    run_sync()
