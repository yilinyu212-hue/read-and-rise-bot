import os
import requests
import feedparser
from datetime import datetime

# --- 1. é…ç½®åŒº (å·²æ›¿æ¢ä¸ºä½ çš„é£ä¹¦å‡­è¯) ---
DEEPSEEK_KEY = "sk-500a770ac8e74c4cb38286ba27164c4a"
APP_ID = "cli_a9e6e2fabcb8dcb2"
APP_SECRET = "6lqhEevwakrsPvEjknF4L8gM0BSGSmLI"
APP_TOKEN = "BNnhbUIMMaQFgKshPnKc7BEInwh"
TABLE_ID = "tblZHZLDmuMr7irX"

SOURCES = {
    "The Economist": "https://www.economist.com/finance-and-economics/rss.xml",
    "Harvard Business Review": "https://hbr.org/rss/topic/leadership",
    "McKinsey Insights": "https://www.mckinsey.com/insights/rss",
    "Fast Company": "https://www.fastcompany.com/leadership/rss",
    "Forbes Leadership": "https://www.forbes.com/leadership/feed/"
}

# --- 2. è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ ---
def get_feishu_token():
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    res = requests.post(url, json={"app_id": APP_ID, "app_secret": APP_SECRET}).json()
    return res.get("tenant_access_token")

# --- 3. è°ƒç”¨ AI ç”Ÿæˆæ‘˜è¦ (è®©ä½ çš„ç½‘é¡µæ›´æœ‰æ–™) ---
def get_ai_summary(title):
    try:
        url = "https://api.deepseek.com/chat/completions"
        headers = {"Authorization": f"Bearer {DEEPSEEK_KEY}", "Content-Type": "application/json"}
        prompt = f"ä½ æ˜¯ä¸€ä½èµ„æ·±æ•™è‚²è€…ã€‚è¯·ä¸ºè¿™ç¯‡æ–‡ç« æ ‡é¢˜å†™ä¸€æ®µ50å­—ä»¥å†…çš„ä¸­æ–‡å¯¼è¯»ï¼Œçªå‡ºå…¶å¯¹é¢†å¯¼è€…çš„å¯å‘ï¼š{title}"
        data = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7
        }
        res = requests.post(url, headers=headers, json=data).json()
        return res['choices'][0]['message']['content']
    except:
        return "å†…å®¹æ­£åœ¨æ·±åº¦è§£æä¸­ï¼Œç¨åæ›´æ–°..."

# --- 4. å†™å…¥é£ä¹¦å¤šç»´è¡¨æ ¼ ---
def write_to_feishu(token, title, link, summary):
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    
    # æ³¨æ„ï¼šè¿™é‡Œçš„å­—æ®µåå¿…é¡»ä¸ä½ é£ä¹¦è¡¨æ ¼é‡Œçš„åˆ—åå®Œå…¨ä¸€è‡´
    data = {
        "fields": {
            "åŸ¹è®­ä¸»é¢˜": title,
            "æ ¸å¿ƒå†…å®¹": summary,
            "åˆ†ç±»": "å¤–åˆŠ",
            "é“¾æ¥": {"url": link, "title": "é˜…è¯»åŸæ–‡"},
            "æ—¶é—´": int(datetime.now().timestamp() * 1000)
        }
    }
    res = requests.post(url, headers=headers, json=data).json()
    return res.get("code") == 0

# --- 5. ä¸»è¿è¡Œé€»è¾‘ ---
def run_pipeline():
    print("ğŸ“¡ æ­£åœ¨å¯åŠ¨ Read & Rise è‡ªåŠ¨åŒ–çˆ¬è™«...")
    token = get_feishu_token()
    if not token:
        print("âŒ é£ä¹¦æˆæƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥ Secret")
        return

    for source_name, url in SOURCES.items():
        print(f"ğŸ” æ­£åœ¨æ‰«æ: {source_name}")
        feed = feedparser.parse(url)
        for entry in feed.entries[:2]: # æ¯ä¸ªæºæŠ“2ç¯‡æœ€æ–°çš„
            print(f"ğŸ“– å‘ç°æ–‡ç« : {entry.title}")
            
            # è¿™é‡Œçš„ AI æ€»ç»“æ˜¯å…³é”®ï¼Œä¼šè®©ä½ çš„ ima å­¦ä¹ å¾—æ›´æ·±å…¥
            summary = get_ai_summary(entry.title)
            
            success = write_to_feishu(token, entry.title, entry.link, summary)
            if success:
                print(f"âœ… æˆåŠŸåŒæ­¥è‡³é£ä¹¦")
            else:
                print(f"âš ï¸ åŒæ­¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¡¨æ ¼å­—æ®µåæ˜¯å¦åŒ¹é…")

if __name__ == "__main__":
    run_pipeline()
