import os, feedparser, requests, json
from datetime import datetime

# --- é…ç½®åŒº ---
DEEPSEEK_KEY = os.environ.get("DEEPSEEK_API_KEY")
UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"

# 1. æ–‡ç« è§£æå‡½æ•° (æ•™ç ”è®²ä¹‰çº§åˆ«)
def get_ai_article_data(title):
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {DEEPSEEK_KEY}"}
    prompt = f"""
    ä½œä¸ºé¡¶çº§è‹±è¯­åŸ¹è®­å¸ˆä¸ç®¡ç†æ•™ç»ƒï¼Œè¯·é’ˆå¯¹ã€Š{title}ã€‹åˆ¶ä½œè®²ä¹‰ã€‚
    å¿…é¡»ä¸¥æ ¼æŒ‰ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºï¼š
    {{
      "level": "Advanced (C1)", 
      "tags": ["Leadership", "Strategy"],
      "en_excerpt": "æŒ‘é€‰æ–‡ä¸­60-100å­—åŒ…å«é«˜é˜¶å¥æ³•çš„æ ¸å¿ƒæ®µè½ã€‚",
      "cn_translation": "ä¸“å®¶çº§ä¸­æ–‡ç¿»è¯‘ã€‚",
      "vocabulary_pro": "Markdownæ ¼å¼ï¼š3ä¸ªé«˜é˜¶è¯æ±‡åŠèŒåœºåº”ç”¨ã€‚",
      "syntax_analysis": "Markdownæ ¼å¼ï¼šè§£ææ–‡ä¸­çš„é•¿éš¾å¥ã€‚",
      "output_playbook": {{
          "speaking": "å¦‚æœä½ åœ¨ä¼šè®®ä¸­å¼•ç”¨æ­¤æ–‡ï¼Œè¯¥å¦‚ä½•è¡¨è¾¾ã€‚",
          "writing": "å‘¨æŠ¥æˆ–é‚®ä»¶ä¸­å¯å¥—ç”¨çš„é«˜é˜¶å¥å‹ã€‚"
      }},
      "insight": "å¯¹ç®¡ç†è€…çš„3ç‚¹é€»è¾‘æ´å¯Ÿã€‚"
    }}
    """
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "system", "content": "You are a professional Business English coach."},
                     {"role": "user", "content": prompt}],
        "response_format": {"type": "json_object"}
    }
    try:
        res = requests.post("https://api.deepseek.com/chat/completions", headers=headers, json=data, timeout=60)
        return json.loads(res.json()['choices'][0]['message']['content'])
    except Exception as e:
        print(f"AI Article Error: {e}")
        return None

# 2. ä¹¦ç±è§£æå‡½æ•° (Atomic Habits ä¸“ç”¨åŠé€šç”¨)
def get_book_insight(book_name, author):
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {DEEPSEEK_KEY}"}
    prompt = f"""
    è¯·ä¸ºç»å…¸ä¹¦ç±ã€Š{book_name}ã€‹ï¼ˆä½œè€…ï¼š{author}ï¼‰åˆ¶ä½œæ•™æ¡ˆã€‚
    å¿…é¡»æŒ‰ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºï¼š
    {{
      "intro": "æ ¸å¿ƒä»·å€¼ç®€ä»‹ (åŒè¯­)ã€‚",
      "takeaways": ["é‡ç‚¹1 (å«è‹±è¯­å…³é”®è¯å’Œç®¡ç†å­¦è§£æ)", "é‡ç‚¹2", "é‡ç‚¹3"],
      "why_read": "æ¨èç†ç”±ï¼šä¸ºä»€ä¹ˆç®¡ç†è€…å¿…é¡»è¯»è¿™æœ¬ä¹¦ï¼Ÿ",
      "image_query": "productivity,minimalist,office"
    }}
    """
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "system", "content": "You are a world-class management consultant."},
                     {"role": "user", "content": prompt}],
        "response_format": {"type": "json_object"}
    }
    try:
        res = requests.post("https://api.deepseek.com/chat/completions", headers=headers, json=data, timeout=60)
        return json.loads(res.json()['choices'][0]['message']['content'])
    except Exception as e:
        print(f"AI Book Error: {e}")
        return None

# --- ä¸»ç¨‹åº ---
def run():
    # æ•°æ®æºé…ç½®
    SOURCES = [
        {"name": "HBR", "url": "https://hbr.org/rss/topic/leadership"},
        {"name": "Economist", "url": "https://www.economist.com/briefing/rss.xml"},
        {"name": "WSJ", "url": "https://feeds.a.dj.com/rss/WSJBusiness.xml"},
        {"name": "Fortune", "url": "https://fortune.com/feed/"},
        {"name": "FT", "url": "https://www.ft.com/?format=rss"},
        {"name": "Forbes", "url": "https://www.forbes.com/innovation/feed/"},
        {"name": "MIT Tech", "url": "https://www.technologyreview.com/feed/"},
        {"name": "Atlantic", "url": "https://www.theatlantic.com/feed/all/"}
    ]
    
    BOOK_LIST = [
        {"title": "Atomic Habits", "author": "James Clear", "tag": "Personal Growth"},
        {"title": "The Pyramid Principle", "author": "Barbara Minto", "tag": "Logic"},
        {"title": "High Output Management", "author": "Andrew Grove", "tag": "Leadership"}
    ]

    os.makedirs('data', exist_ok=True)
    all_articles = []
    all_books = []

    # å¼•æ“1: å¤„ç†å¤–åˆŠæ–‡ç« 
    print("ğŸš€ å¯åŠ¨å¤–åˆŠæ•™ç ”å¼•æ“...")
    for src in SOURCES:
        try:
            resp = requests.get(src['url'], headers={"User-Agent": UA}, timeout=15)
            feed = feedparser.parse(resp.content)
            if feed.entries:
                entry = feed.entries[0]
                print(f"ğŸ“˜ ç ”è¯»ä¸­: {entry.title}")
                ai_data = get_ai_article_data(entry.title)
                if ai_data:
                    ai_data.update({
                        "source": src['name'],
                        "title": entry.title,
                        "date": datetime.now().strftime("%Y-%m-%d"),
                        "link": entry.link
                    })
                    all_articles.append(ai_data)
        except Exception as e:
            print(f"Source {src['name']} skip due to error: {e}")

    # å¼•æ“2: å¤„ç†æ¨èä¹¦ç±
    print("ğŸ“š å¯åŠ¨ä¹¦æ¶è§£æå¼•æ“...")
    for b in BOOK_LIST:
        print(f"ğŸ“– æ­£åœ¨è§£æåè‘—: {b['title']}")
        insight = get_book_insight(b['title'], b['author'])
        if insight:
            # è‡ªåŠ¨åŒ¹é… Unsplash å•†åŠ¡å›¾ç‰‡
            img_url = f"https://images.unsplash.com/photo-1544716278-ca5e3f4abd8c?auto=format&fit=crop&w=800&q=80" # å¤‡ç”¨é«˜è´¨é‡ä¹¦æ¶å›¾
            all_books.append({
                "title": b['title'],
                "author": b['author'],
                "tag": b['tag'],
                "img": img_url,
                **insight
            })

    # --- å…³é”®ï¼šå¼ºåˆ¶ä¿å­˜æ•°æ® ---
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜æ•°æ®... æ–‡ç« :{len(all_articles)}, ä¹¦ç±:{len(all_books)}")
    with open('data/library.json', 'w', encoding='utf-8') as f:
        json.dump(all_articles, f, ensure_ascii=False, indent=4)
    
    with open('data/books.json', 'w', encoding='utf-8') as f:
        json.dump(all_books, f, ensure_ascii=False, indent=4)
    
    print("âœ… æ•°æ®åŒæ­¥åœ†æ»¡å®Œæˆï¼")

if __name__ == "__main__":
    run()
