import os, feedparser, json, requests
from datetime import datetime
from notion_client import Client

# ä» GitHub Secrets ä¸­è¯»å–é…ç½®
DEEPSEEK_KEY = os.environ.get("DEEPSEEK_API_KEY")
NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
DATABASE_ID = os.environ.get("DATABASE_ID")

notion = Client(auth=NOTION_TOKEN)

def get_ai_analysis(title):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_KEY}"
    }
    data = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½Read & Riseæ•™è‚²ç­–å±•äººã€‚è¯·ç”¨ä¸­æ–‡æ€»ç»“æ ¸å¿ƒè§‚ç‚¹ã€æ ‡æ³¨éš¾åº¦å¹¶æå–3ä¸ªé‡ç‚¹è¯æ±‡ã€‚"},
            {"role": "user", "content": f"æ–‡ç« æ ‡é¢˜: {title}"}
        ]
    }
    try:
        res = requests.post("https://api.deepseek.com/chat/completions", headers=headers, json=data, timeout=30)
        return res.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"AIè§£æç”Ÿæˆä¸­... (é”™è¯¯è¯¦æƒ…: {e})"

def push_to_notion(title, link, content):
    try:
        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å° ID é•¿åº¦ç¡®ä¿ Secret å·²ç”Ÿæ•ˆ
        print(f"DEBUG: å°è¯•æ¨é€è‡³ Database ID (é•¿åº¦: {len(DATABASE_ID)})")
        
        notion.pages.create(
            parent={"database_id": DATABASE_ID},
            properties={
                "Name": {"title": [{"text": {"content": title}}]},
                "Source": {"select": {"name": "Economist"}}, 
                "Link": {"url": link},                       
                "AI Summary": {"rich_text": [{"text": {"content": content[:1900]}}]}, 
                "Date": {"date": {"start": datetime.now().strftime("%Y-%m-%d")}},
                "Status": {"status": {"name": "To Read"}}  # åŒ¹é…ä½ çœ‹æ¿ä¸­çš„ 'To Read' çŠ¶æ€
            }
        )
        print(f"ğŸš€ æˆåŠŸåŒæ­¥ä¸€ç¯‡æ–‡ç« åˆ° Notion: {title[:20]}...")
    except Exception as e:
        print(f"âŒ Notion æ¨é€å¤±è´¥ã€‚é”™è¯¯åŸå› : {e}")

def run():
    # çˆ¬å–ç»æµå­¦äºº Briefing æ ç›®
    feed = feedparser.parse("https://www.economist.com/briefing/rss.xml")
    articles = []
    
    # æ¯æ¬¡å¤„ç†å‰ 3 ç¯‡
    for entry in feed.entries[:3]:
        print(f"æ­£åœ¨å¤„ç†: {entry.title}")
        analysis = get_ai_analysis(entry.title)
        
        articles.append({
            "title": entry.title, 
            "link": entry.link, 
            "content": analysis, 
            "date": datetime.now().strftime("%Y-%m-%d")
        })
        
        if NOTION_TOKEN and DATABASE_ID:
            push_to_notion(entry.title, entry.link, analysis)

    # ä¿å­˜æœ¬åœ° library.json
    os.makedirs('data', exist_ok=True)
    with open('data/library.json', 'w', encoding='utf-8') as f:
        json.dump(articles, f, ensure_ascii=False, indent=4)

if __name__ == "__main__":
    run()
