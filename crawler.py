import requests
import feedparser
import json
import os
import time
from datetime import datetime

# ================= 1. é…ç½®ä¸ç¯å¢ƒå˜é‡ =================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# 12 ä¸ªå…¨çƒé¡¶å°–å•†ä¸šä¸ç§‘æŠ€æ™ºåº“æº
RSS_SOURCES = [
    {"name": "Harvard Business Review", "url": "https://hbr.org/rss/feed/topics/leadership"},
    {"name": "McKinsey Insights", "url": "https://www.mckinsey.com/insights/rss"},
    {"name": "BCG Global", "url": "https://www.bcg.com/rss.xml"},
    {"name": "The Economist", "url": "https://www.economist.com/business/rss.xml"},
    {"name": "MIT Technology Review", "url": "https://www.technologyreview.com/feed/"},
    {"name": "Financial Times", "url": "https://www.ft.com/management?format=rss"},
    {"name": "Strategy+Business", "url": "https://www.strategy-business.com/rss/all_articles"},
    {"name": "Knowledge at Wharton", "url": "https://knowledge.wharton.upenn.edu/feed/"},
    {"name": "Fast Company", "url": "https://www.fastcompany.com/latest/rss"},
    {"name": "Wired Business", "url": "https://www.wired.com/feed/category/business/latest/rss"},
    {"name": "Fortune", "url": "https://fortune.com/feed/"},
    {"name": "TechCrunch", "url": "https://techcrunch.com/category/enterprise/feed/"}
]

# æ‚¨å¸Œæœ› AI ç”Ÿæˆç²¾è¯»ç¬”è®°çš„ä¹¦ç±æ¸…å•
BOOKS_TO_READ = [
    "ã€ŠThe Second Curveã€‹- Charles Handy",
    "ã€ŠPrinciplesã€‹- Ray Dalio",
    "ã€ŠHigh Output Managementã€‹- Andrew Grove",
    "ã€ŠZero to Oneã€‹- Peter Thiel",
    "ã€ŠBuilt to Lastã€‹- Jim Collins"
]

# ================= 2. AI è§£æå¼•æ“ =================
def ai_call(prompt):
    """é€šç”¨çš„ AI è°ƒç”¨é€»è¾‘ï¼ŒåŒ…å«ä¸¥æ ¼çš„ JSON æ¸…æ´—"""
    url = "https://api.deepseek.com/chat/completions"
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    try:
        data = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3
        }
        response = requests.post(url, headers=headers, json=data, timeout=60)
        res_json = response.json()
        content = res_json['choices'][0]['message']['content'].strip()
        
        # å¼ºåŠ›æ¸…æ´—ï¼šå‰”é™¤ Markdown çš„ json æ ‡ç­¾
        if "```" in content:
            content = content.split("```")[1].replace("json", "").strip()
        
        return json.loads(content)
    except Exception as e:
        print(f"âŒ AI è§£æå¼‚å¸¸: {e}")
        return None

def analyze_article(title, source_name):
    """å¤–åˆŠæ·±åº¦æ‹†è§£ Prompt"""
    prompt = f"""
    You are a world-class AI Business Coach. Analyze article "{title}" from {source_name}.
    Output STRICTLY in JSON:
    {{
      "en_summary": "3 executive bullet points in English.",
      "cn_analysis": "### ğŸ§  æ€ç»´æ¨¡å‹\\n[åç§°åŠé€»è¾‘]\\n\\n### ğŸ› ï¸ å†³ç­–å»ºè®®\\n[è¡ŒåŠ¨æŒ‡å¼•]",
      "scores": {{"æˆ˜ç•¥æ€ç»´": 80, "ç»„ç»‡è¿›åŒ–": 80, "å†³ç­–éŸ§æ€§": 80, "è¡Œä¸šæ´å¯Ÿ": 80, "æŠ€æœ¯è§†é‡": 80}},
      "vocabulary": {{"Term": "Chinese Meaning"}}
    }}
    """
    return ai_call(prompt)

def analyze_book(book_name):
    """ä¹¦ç±ç²¾è¯»ç¬”è®° Prompt"""
    prompt = f"""
    You are an Executive Educator. Provide a deep summary for the book "{book_name}".
    Output STRICTLY in JSON:
    {{
      "book_title": "{book_name}",
      "first_principle": "The one core underlying logic of this book.",
      "insights": ["Key Insight 1", "Key Insight 2", "Key Insight 3"],
      "executive_phrasing": "One powerful English sentence for a high-level meeting."
    }}
    """
    return ai_call(prompt)

# ================= 3. ä¸»è¿è¡Œæµç¨‹ =================
def run_sync():
    # åˆå§‹åŒ–æ•°æ®ç»“æ„ï¼ŒåŒºåˆ†æ–‡ç« å’Œä¹¦ç±
    final_data = {
        "articles": [],
        "books": [],
        "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M")
    }
    
    # --- ä»»åŠ¡ A: åŒæ­¥ 12 ä¸ªå¤–åˆŠæº ---
    print(f"ğŸ“¡ å¯åŠ¨å…¨çƒæ™ºåº“åŒæ­¥ (å…± {len(RSS_SOURCES)} ä¸ªæº)...")
    for source in RSS_SOURCES:
        try:
            print(f"æ­£åœ¨æŠ“å–: {source['name']}...")
            feed = feedparser.parse(source['url'])
            # æ¯ä¸ªæºå–æœ€æ–° 1 ç¯‡ï¼Œç¡®ä¿å¤šæ ·æ€§
            for item in feed.entries[:1]:
                analysis = analyze_article(item.title, source['name'])
                if analysis:
                    analysis.update({
                        "title": item.title,
                        "link": item.link,
                        "source": source['name']
                    })
                    final_data["articles"].append(analysis)
            time.sleep(1.2) # ç¤¼è²Œé—´æ–­
        except Exception as e:
            print(f"âŒ {source['name']} æŠ“å–å¤±è´¥: {e}")

    # --- ä»»åŠ¡ B: ç”Ÿæˆä¹¦ç±ç²¾è¯»ç¬”è®° ---
    print(f"ğŸ“š å¯åŠ¨ AI ç²¾è¯»ç¬”è®°ç”Ÿæˆ (å…± {len(BOOKS_TO_READ)} æœ¬ä¹¦)...")
    for book in BOOKS_TO_READ:
        print(f"æ­£åœ¨é¢†è¯»: {book}...")
        book_res = analyze_book(book)
        if book_res:
            final_data["books"].append(book_res)
        time.sleep(1.5)

    # --- ä»»åŠ¡ C: æŒä¹…åŒ–å­˜å‚¨ ---
    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(final_data, f, ensure_ascii=False, indent=4)
    
    print(f"âœ… åŒæ­¥å®Œæˆï¼ä»Šæ—¥å†…å‚: {len(final_data['articles'])} ç¯‡, ä¹¦ç±ç¬”è®°: {len(final_data['books'])} æœ¬ã€‚")

if __name__ == "__main__":
    run_sync()
